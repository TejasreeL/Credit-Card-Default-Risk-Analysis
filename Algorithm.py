# -*- coding: utf-8 -*-
"""Credit card.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LecxrDLr-Zi8_-rqJVpzTF7JyDmucQve

Problem Statement :  Can we use data and machine learning to predict who might miss credit card payments/loan/Mortgages, allowing banks to offer help (like lower rates or financial advice) and prevent defaults for both parties benefit.

This essentially turns credit risk analysis into a predictive game with the goal of helping both banks and borrowers

Solution :

*   Lower interest rates or smaller payments:
*   Making things easier financially.
Payment plans or debt consolidation: Helping them manage their debt better.
* Financial education: Teaching them better budgeting and spending habits.

**Importing Libraries and packages**
"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import pandas as pd

df = pd.read_excel("tips.xlsx", index_col=0)

df.head()

df.shape

df = df.iloc[1:].reset_index(drop=True)

plt.figure(figsize=(6, 4))
plt.bar(df['Y'].value_counts().index, df['Y'].value_counts())
plt.title('Distribution of Defaulters (1) and Non-Defaulters (0)')
plt.xlabel('Default Status')
plt.ylabel('Count')
plt.show()

correlation_matrix = df.corr()

# import seaborn as sns
# plt.figure(figsize=(14, 10))
# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
# plt.title('Correlation Matrix')
# plt.show()

df.head()

df.info()

df.describe()

df.isnull().sum()

"""**Checking Whether Dataset contain any null Val.**"""

import missingno as msno
msno.matrix(df)

import matplotlib.pyplot as plt
import seaborn as sns

print(df.columns)

df.head()['X1']

plt.figure(figsize=(16, 12))

plt.subplot(3, 3, 1)
sns.countplot(x='Y', data=df, palette='viridis')
plt.title('Distribution of Default Payments')

features = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11',
       'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21',
       'X22', 'X23']
target = 'Y'

X = df[features]
y = df[target]
# print(X,y)

plt.figure(figsize=(8, 6))
sns.countplot(x='X1', data=df, palette='dark')
plt.title('Distribution of Amount of Credit (X1)')
plt.xlabel('Amount of Credit')
plt.ylabel('Frequency')
plt.show()

from sklearn.preprocessing import LabelEncoder
y_train = df['Y']
le = LabelEncoder()
df['Y'] = le.fit_transform(df['Y'])
df['Y'] = df['Y'].astype(float)

print(df['Y'].dtype)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""#Logistic Regression"""

model = LogisticRegression(random_state=42)

print(y_train.unique())

print(y_train.isnull().sum())

y_train = y_train.astype(float)

y_train.dtype

print(y_train.value_counts())

# print(X_train_scaled.value_counts())

print(X_train_scaled.dtype)

model.fit(X_train_scaled, y_train)

y_train.replace('unknown', -1, inplace=True)
y_test.replace('unknown', -1, inplace=True)

print(y_train.unique())
print(y_test.unique())

y_train = y_train.astype(int)
y_test = y_test.astype(int)

y_pred = model.predict(X_test_scaled)

accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)


print(f"Accuracy: {accuracy:.2f}")
print("\nConfusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(classification_rep)

from sklearn.ensemble import RandomForestClassifier
import numpy as np

"""#Random Forest Classifier"""

classifier = RandomForestClassifier()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

y_pred

accuracy_score(y_test, y_pred)

confusion_matrix(y_test, y_pred)

print(classification_report(y_test, y_pred))

X = df.iloc[:, 0:23]
X

y = df['Y'].values.flatten()
y

type(y)

import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()
classifier.add(Dense(units=12, kernel_initializer='uniform', activation='relu', input_dim=23))
classifier.add(Dense(units=12, kernel_initializer='uniform', activation='relu'))
classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))

train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.1, random_state = 12)

classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

import numpy as np

train_x = np.array(X_train)
train_y = np.array(y_train)

classifier.fit(train_x, train_y, batch_size=10, epochs=100)

